{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小王在三月的工资为5000\n"
     ]
    }
   ],
   "source": [
    "name=\"小王\"\n",
    "month=\"三月\"\n",
    "print(\"{}在{}的工资为{}\".format(name, month,5000))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T09:42:17.639150Z",
     "start_time": "2024-03-21T09:42:17.621898Z"
    }
   },
   "id": "b2ce4dc23adafb21",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [61]\u001B[0m, in \u001B[0;36m<cell line: 30>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# 调用推理函数\u001B[39;00m\n\u001B[0;32m     29\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbest.pt\u001B[39m\u001B[38;5;124m'\u001B[39m  \u001B[38;5;66;03m# 确保这是你的模型文件的正确路径\u001B[39;00m\n\u001B[1;32m---> 30\u001B[0m \u001B[43minfer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [61]\u001B[0m, in \u001B[0;36minfer\u001B[1;34m(model_path)\u001B[0m\n\u001B[0;32m     12\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# 加载模型\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m model\u001B[38;5;241m.\u001B[39meval()  \u001B[38;5;66;03m# 设置为评估模式\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# 准备输入数据\u001B[39;00m\n",
      "Input \u001B[1;32mIn [61]\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(model_path, device)\u001B[0m\n\u001B[0;32m      5\u001B[0m     device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(model_path, map_location\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m(device)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'dict' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "def load_model(model_path, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "    return model.to(device)\n",
    "def prepare_input(device, batch_size=1, channels=3, height=640, width=640):\n",
    "    x = torch.randn(batch_size, channels, height, width, device=device)\n",
    "    return x\n",
    "def infer(model_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # 加载模型\n",
    "    model = load_model(model_path, device)\n",
    "    model.eval()  # 设置为评估模式\n",
    "    \n",
    "    # 准备输入数据\n",
    "    x = prepare_input(device)\n",
    "    \n",
    "    # 执行前向传播\n",
    "    with torch.no_grad():\n",
    "        output = model(x)\n",
    "    \n",
    "    # 打印输出的形状（作为示例）\n",
    "    print(output.size())\n",
    "\n",
    "# 调用推理函数\n",
    "model_path = 'best.pt'  # 确保这是你的模型文件的正确路径\n",
    "infer(model_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T09:46:58.312864Z",
     "start_time": "2024-03-21T09:46:58.190631Z"
    }
   },
   "id": "36a3f640b19d4fd8",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam found at index: 0\n",
      "Webcam found at index: 1\n",
      "Webcam found at index: 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "for i in range(100):\n",
    "    cap = cv2.VideoCapture(i)\n",
    "    if cap.isOpened():\n",
    "        print('Webcam found at index: ' + str(i))\n",
    "        cap.release()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T05:02:51.933839Z",
     "start_time": "2024-03-22T05:02:38.898795Z"
    }
   },
   "id": "37d52c28af6ed76e",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "video = cv2.VideoCapture(\"rtmp://localhost:1935/live/123\")\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print(fps)\n",
    "size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "print(size)\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    cv2.imshow(\"A video\", frame)\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-22T05:56:37.681700Z"
    }
   },
   "id": "b8bda6d7db967410",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "\n",
    "# 加载第一张照片并识别面部特征\n",
    "image1 = face_recognition.load_image_file(\"C:/Users/wsh/Pictures/Camera Roll/f1.jpg\")\n",
    "encoding1 = face_recognition.face_encodings(image1)[0]\n",
    "\n",
    "# 加载第二张照片并识别面部特征\n",
    "image2 = face_recognition.load_image_file(\"C:/Users/wsh/Pictures/Camera Roll/f2.jpg\")\n",
    "encoding2 = face_recognition.face_encodings(image2)[0]\n",
    "\n",
    "# 比较两个面部特征\n",
    "results = face_recognition.compare_faces([encoding1], encoding2)\n",
    "\n",
    "if results[0]:\n",
    "    print(\"这两张照片是同一个人。\")\n",
    "else:\n",
    "    print(\"这两张照片不是同一个人。\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-23T09:34:57.719094Z"
    }
   },
   "id": "60b650cd9a6563f8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  b437241 torch 2.2.0+cu118 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x08'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnpicklingError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 29\u001B[0m\n\u001B[0;32m     27\u001B[0m HIDE_CONF \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# 是否隐藏置信度\u001B[39;00m\n\u001B[0;32m     28\u001B[0m HIDE_LABELS \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# 是否隐藏标签\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m model, device, half, stride, names \u001B[38;5;241m=\u001B[39m \u001B[43mget_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m imgsz \u001B[38;5;241m=\u001B[39m check_img_size([\u001B[38;5;241m640\u001B[39m, \u001B[38;5;241m640\u001B[39m], s\u001B[38;5;241m=\u001B[39mstride)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcolors\u001B[39m(index, bright\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32mD:\\Smoke\\SmokeDetectionMasterPython\\importYoloPt.py:10\u001B[0m, in \u001B[0;36mget_model\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m device \u001B[38;5;241m=\u001B[39m select_device(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m half \u001B[38;5;241m=\u001B[39m device\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 10\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mattempt_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mWEIGHTS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m stride \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(model\u001B[38;5;241m.\u001B[39mstride\u001B[38;5;241m.\u001B[39mmax())  \u001B[38;5;66;03m# model stride\u001B[39;00m\n\u001B[0;32m     12\u001B[0m names \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mmodule\u001B[38;5;241m.\u001B[39mnames \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodule\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m model\u001B[38;5;241m.\u001B[39mnames  \u001B[38;5;66;03m# get class names\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Smoke\\SmokeDetectionMasterPython\\models\\experimental.py:96\u001B[0m, in \u001B[0;36mattempt_load\u001B[1;34m(weights, map_location, inplace, fuse)\u001B[0m\n\u001B[0;32m     94\u001B[0m model \u001B[38;5;241m=\u001B[39m Ensemble()\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m weights \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(weights, \u001B[38;5;28mlist\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [weights]:\n\u001B[1;32m---> 96\u001B[0m     ckpt \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattempt_download\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmap_location\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# load\u001B[39;00m\n\u001B[0;32m     97\u001B[0m     ckpt \u001B[38;5;241m=\u001B[39m (ckpt\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mema\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m ckpt[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mfloat()  \u001B[38;5;66;03m# FP32 model\u001B[39;00m\n\u001B[0;32m     98\u001B[0m     model\u001B[38;5;241m.\u001B[39mappend(ckpt\u001B[38;5;241m.\u001B[39mfuse()\u001B[38;5;241m.\u001B[39meval() \u001B[38;5;28;01mif\u001B[39;00m fuse \u001B[38;5;28;01melse\u001B[39;00m ckpt\u001B[38;5;241m.\u001B[39meval())  \u001B[38;5;66;03m# fused or un-fused model in eval mode\u001B[39;00m\n",
      "File \u001B[1;32mD:\\conda_home\\envs\\yolov5-master\\lib\\site-packages\\torch\\serialization.py:1040\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1038\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1039\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1040\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n",
      "File \u001B[1;32mD:\\conda_home\\envs\\yolov5-master\\lib\\site-packages\\torch\\serialization.py:1258\u001B[0m, in \u001B[0;36m_legacy_load\u001B[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1252\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(f, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreadinto\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39mversion_info \u001B[38;5;241m<\u001B[39m (\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m2\u001B[39m):\n\u001B[0;32m   1253\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1254\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1255\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived object of type \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(f)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1256\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunctionality.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1258\u001B[0m magic_number \u001B[38;5;241m=\u001B[39m pickle_module\u001B[38;5;241m.\u001B[39mload(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1259\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m magic_number \u001B[38;5;241m!=\u001B[39m MAGIC_NUMBER:\n\u001B[0;32m   1260\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid magic number; corrupt file?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mUnpicklingError\u001B[0m: invalid load key, '\\x08'."
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyexpat import model\n",
    "from typing import List, Any\n",
    "import asyncio\n",
    "import aiomysql\n",
    "import cv2\n",
    "import jwt\n",
    "import numpy as np\n",
    "import torch\n",
    "from starlette.responses import JSONResponse\n",
    "\n",
    "from MysqlUtils.init import register_mysql\n",
    "from RedisUtils.init import register_redis\n",
    "from SmokingDecisionMaker import SmokingDecisionMaker\n",
    "from configList import *\n",
    "from importYoloPt import get_model\n",
    "from utils.ConfigReader import ConfigReader\n",
    "from utils.augmentations import letterbox\n",
    "from utils.general import check_img_size, non_max_suppression, scale_coords\n",
    "from utils.plots import Annotator\n",
    "WEIGHTS = 'weights/yolov5n.pt'\n",
    "IMGSZ = [640, 640]  # 图像尺寸\n",
    "CONF_THRES = 0.5  # 置信度阈值\n",
    "IOU_THRES = 0.2  # IOU阈值\n",
    "MAX_DET = 1000  # 最大检测数量\n",
    "LINE_THICKNESS = 1  # 线条厚度\n",
    "HIDE_CONF = False  # 是否隐藏置信度\n",
    "HIDE_LABELS = None  # 是否隐藏标签\n",
    "model, device, half, stride, names = get_model()\n",
    "imgsz = check_img_size([640, 640], s=stride)\n",
    "def colors(index, bright=True):\n",
    "    color_list = [(0, 0, 255), (0, 255, 0), (255, 0, 0)]\n",
    "    return color_list[index % len(color_list)]\n",
    "\n",
    "def pred_img_optimized_async(img0, model, device, imgsz, names, conf_thres, iou_thres, half,\n",
    "                                   line_thickness, hide_labels, hide_conf, max_det):\n",
    "        img = letterbox(img0, new_shape=imgsz, auto=True)[0]\n",
    "        img = img.transpose((2, 0, 1))[::-1]\n",
    "        img = np.ascontiguousarray(img)\n",
    "\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()\n",
    "        img /= 255.0  # 归一化\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        im0 = img0.copy()\n",
    "        annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "\n",
    "        pred = model(img, augment=False, visualize=False)[0]\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes=None, agnostic=False, max_det=max_det)\n",
    "\n",
    "        detections = []\n",
    "        det = pred[0]\n",
    "        if len(det):\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "                c = int(cls)\n",
    "                detections.append({'coords': tuple(map(int, xyxy)), 'confidence': conf.item()})\n",
    "\n",
    "                label = None if hide_labels else f'{names[c]} {conf:.2f}' if not hide_conf else names[c]\n",
    "                annotator.box_label(xyxy, label, color=colors(c))\n",
    "\n",
    "        return im0, detections\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 用于计算FPS的变量\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 对当前帧进行处理和预测\n",
    "    img, detections =pred_img_optimized_async(frame, model, device, IMGSZ, names, CONF_THRES,\n",
    "                                                               IOU_THRES, half, LINE_THICKNESS, HIDE_LABELS, HIDE_CONF,\n",
    "                                                               MAX_DET)\n",
    "\n",
    "    # 显示处理后的图像\n",
    "    frame_count += 1\n",
    "    elapsed_time = time.time() - start_time\n",
    "    fps = frame_count / elapsed_time\n",
    "\n",
    "    # 将FPS文本写入图像\n",
    "    cv2.putText(img, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # 显示处理后的图像\n",
    "    cv2.imshow('Image', img)\n",
    "    \n",
    "    # 按 'q' 键退出循环\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T04:55:12.151400Z",
     "start_time": "2024-03-24T04:55:12.022361Z"
    }
   },
   "id": "b76dda433f8aa25e",
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
